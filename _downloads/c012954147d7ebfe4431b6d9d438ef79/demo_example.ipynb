{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using the motion energy pyramid class\n\nThis example shows how to extract motion energy features from a video.\n\nFirst, we need to define the video we want to use. In this example, we'll use a small video. The video is 2.5 minutes in duration with a frame rate of 24fps. For the purposes of this example, we'll only use the first 200 frames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nimages = 200\nstimulus_fps = 24\nvideo_file = 'http://anwarnunez.github.io/downloads/avsnr150s24fps_tiny.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <video width=100% height=100% preload=none muted controls>\n    <source src=\"https://anwarnunez.github.io/downloads/avsnr150s24fps_tiny.mp4\" type=\"video/mp4\">\n   </video>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The video is RGB. So, the first step is to convert it to a luminance representation. Internally, this is achieved by converting RGB pixel values to CIE-LAB pixel values and keeping only the \"L\" channel. The function :func:`moten.io.video2luminance` takes care of downloading the video, converting RGB to luminance, and spatial downsampling if needed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import moten\nimport matplotlib.pyplot as plt\nluminance_images = moten.io.video2luminance(video_file, nimages=nimages)\nnimages, vdim, hdim = luminance_images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we need to construct the motion energy pyramid. To achieve this, we must provide the size of the stimulus frames in pixels (``vdim`` and ``hdim``) and also the frame rate\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pyramid = moten.pyramids.MotionEnergyPyramid(stimulus_vhsize=(vdim, hdim),\n                                             stimulus_fps=stimulus_fps)\n\nprint(pyramid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use the method ``project_stimulus`` to compute the motion energy features (see :meth:`moten.pyramids.MotionEnergyPyramid.project_stimulus`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features = pyramid.project_stimulus(luminance_images)\nprint(features.shape)\nfig, ax = plt.subplots(figsize=(12, 12))\nax.matshow(features, aspect='auto')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}